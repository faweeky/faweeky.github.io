<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>基于scrapy构建百科爬虫 | 猫叔的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="1. scrapyScrapy是基于python开发的一个快速web抓取框架，用于抓取web站点页面并从中提取结构化的数据。基于scrapy提供的框架，可以快速编写具有基本功能的爬虫，同时，通过继承并扩展scrapy提供的不同爬虫类，可以快速构建功能强大高效的爬虫。scrapy中重要的文件有：

items.py： 定义需要从网页中提取的结构化数据类item，并提供对结构化数据的键-值对访问。
p">
<meta property="og:type" content="article">
<meta property="og:title" content="基于scrapy构建百科爬虫">
<meta property="og:url" content="http://yoursite.com/2015/08/17/20150817-Scrapy-BaikeSpider-md/index.html">
<meta property="og:site_name" content="猫叔的博客">
<meta property="og:description" content="1. scrapyScrapy是基于python开发的一个快速web抓取框架，用于抓取web站点页面并从中提取结构化的数据。基于scrapy提供的框架，可以快速编写具有基本功能的爬虫，同时，通过继承并扩展scrapy提供的不同爬虫类，可以快速构建功能强大高效的爬虫。scrapy中重要的文件有：

items.py： 定义需要从网页中提取的结构化数据类item，并提供对结构化数据的键-值对访问。
p">
<meta property="og:updated_time" content="2015-08-17T02:26:21.721Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="基于scrapy构建百科爬虫">
<meta name="twitter:description" content="1. scrapyScrapy是基于python开发的一个快速web抓取框架，用于抓取web站点页面并从中提取结构化的数据。基于scrapy提供的框架，可以快速编写具有基本功能的爬虫，同时，通过继承并扩展scrapy提供的不同爬虫类，可以快速构建功能强大高效的爬虫。scrapy中重要的文件有：

items.py： 定义需要从网页中提取的结构化数据类item，并提供对结构化数据的键-值对访问。
p">
  
    <link rel="alternative" href="/atom.xml" title="猫叔的博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="http://7xl0b5.com1.z0.glb.clouddn.com/maoshu.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">猫叔的博客</a></h1>
		</hgroup>

		
		<p class="header-subtitle">读书、跑步、写字等等</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="http://www.github.com/faweeky" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="http://weibo.com/faweeky" title="weibo">weibo</a>
					        
								<a class="zhihu" target="_blank" href="http://www.zhihu.com/people/feng-xiao-zhou" title="zhihu">zhihu</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/R语言/" style="font-size: 10px;">R语言</a> <a href="/tags/duoshuo/" style="font-size: 10px;">duoshuo</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/tags/mysql/" style="font-size: 10px;">mysql</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/quantmod/" style="font-size: 10px;">quantmod</a> <a href="/tags/redis/" style="font-size: 10px;">redis</a> <a href="/tags/scrapy/" style="font-size: 10px;">scrapy</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">reading more, thinking more</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">猫叔的博客</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="http://7xl0b5.com1.z0.glb.clouddn.com/maoshu.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">猫叔的博客</h1>
			</hgroup>
			
			<p class="header-subtitle">读书、跑步、写字等等</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="http://www.github.com/faweeky" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="http://weibo.com/faweeky" title="weibo">weibo</a>
			        
						<a class="zhihu" target="_blank" href="http://www.zhihu.com/people/feng-xiao-zhou" title="zhihu">zhihu</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="title-20150817-Scrapy-BaikeSpider-md" class="article article-type-title" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/08/17/20150817-Scrapy-BaikeSpider-md/" class="article-date">
  	<time datetime="2015-08-17T01:52:41.000Z" itemprop="datePublished">2015-08-17</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      基于scrapy构建百科爬虫
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/mysql/">mysql</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/redis/">redis</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/scrapy/">scrapy</a></li></ul>
	</div>

        

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>1. scrapy</strong><br>Scrapy是基于python开发的一个快速web抓取框架，用于抓取web站点页面并从中提取结构化的数据。<br>基于scrapy提供的框架，可以快速编写具有基本功能的爬虫，同时，通过继承并扩展scrapy提供的不同爬虫类，可以快速构建功能强大高效的爬虫。<br>scrapy中重要的文件有：</p>
<ol>
<li>items.py： 定义需要从网页中提取的结构化数据类item，并提供对结构化数据的<strong>键-值对</strong>访问。</li>
<li>pipelines.py: 定义提取出item后的处理流程。每个pipeline收到一个item，再对其进行处理。多个pipeline可以进行串联。例如：可以进行数据进一步清洗、正确性校验、重复性校验还有数据持久化。</li>
<li>spiders.py：定义爬虫。包括获取(crawl)和解析(parse)网页的函数。</li>
</ol>
<a id="more"></a>
<p>![scrapy-process-workflow][<a href="http://7xl0b5.com1.z0.glb.clouddn.com/scrapy.jpg" target="_blank" rel="external">http://7xl0b5.com1.z0.glb.clouddn.com/scrapy.jpg</a>]</p>
<p><strong>2. 定义提取的数据BaikeItem</strong><br>在这里定义从百度百科一个页面中提取的三类数据：百科标题名、百科第一段简介和百科链接。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">class <span class="function"><span class="title">BaikeItem</span><span class="params">(scrapy.Item)</span></span>:</span><br><span class="line">    name = scrapy.<span class="function"><span class="title">Field</span><span class="params">()</span></span></span><br><span class="line">    desc = scrapy.<span class="function"><span class="title">Field</span><span class="params">()</span></span></span><br><span class="line">    link = scrapy.<span class="function"><span class="title">Field</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure>
<p><strong>3. 定义提取的爬虫BaikeSpider</strong></p>
<p>scrapy中提供了几个spider基类，basespider, CrawlSpider, XMLFeedSpider, CVSFeedSpider等。<br>CrawlSpider中提供了Rule的概念，用于提取链接。每个Rule的定义为：<br><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class scrapy.spiders.<span class="keyword">Rule</span>(link_extractor, callback=None, cb_kwargs=None, follow=None, process_links=None, process_request=None)</span><br></pre></td></tr></table></figure></p>
<p>LinkExtractor用于提取链接，CallBack表示对每一个用linkExtrator提取出的链接进行的处理函数，cb_kwargs是CallBack的字典参数表，Follow表示是否将该链接放入访问队列。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">class <span class="function"><span class="title">BaikeSpider</span><span class="params">(CrawlSpider)</span></span>:</span><br><span class="line"></span><br><span class="line">    rules = (</span><br><span class="line">         <span class="function"><span class="title">Rule</span><span class="params">(LinkExtractor(allow=(<span class="string">'baike\.baidu\.com\/view\/'</span>)</span></span>),callback=<span class="string">'parse_item'</span>,                       follow=True),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    def <span class="function"><span class="title">parse_item</span><span class="params">(self, response)</span></span>:</span><br><span class="line">        title = response.<span class="function"><span class="title">xpath</span><span class="params">(<span class="string">'//h1/span[@class="lemmaTitleH1"]/text()'</span>)</span></span>.<span class="function"><span class="title">extract</span><span class="params">()</span></span></span><br><span class="line">        <span class="attribute">content</span> = response.<span class="function"><span class="title">xpath</span><span class="params">(<span class="string">'//div[@class="card-summary-content"]'</span>)</span></span>.<span class="function"><span class="title">xpath</span><span class="params">(<span class="string">'div[@class="para"]'</span>)</span></span>.<span class="function"><span class="title">extract</span><span class="params">()</span></span></span><br><span class="line"></span><br><span class="line">        item = <span class="function"><span class="title">BaikeItem</span><span class="params">()</span></span></span><br><span class="line">        name = title[<span class="number">0</span>]</span><br><span class="line">        desc = soup.<span class="function"><span class="title">get_text</span><span class="params">()</span></span></span><br><span class="line">        item[<span class="string">'link'</span>] = response<span class="class">.url</span></span><br><span class="line"> </span><br><span class="line">        item[<span class="string">'name'</span>]  = name.<span class="function"><span class="title">strip</span><span class="params">()</span></span></span><br><span class="line">        <span class="keyword">if</span> (desc == None or <span class="function"><span class="title">len</span><span class="params">(desc)</span></span> ==<span class="number">0</span> ) :</span><br><span class="line">           item[<span class="string">'desc'</span>] = <span class="string">''</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">           item[<span class="string">'desc'</span>] = desc.<span class="function"><span class="title">strip</span><span class="params">()</span></span></span><br><span class="line"> </span><br><span class="line">        return item</span><br></pre></td></tr></table></figure>
<p><strong>4. 定义处理BaikeItem的BaikePipeline</strong></p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">class <span class="function"><span class="title">BaikePipeline</span><span class="params">(object)</span></span>:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self<span class="class">.dbpool</span> = adbapi.ConnectionPool(<span class="string">'MySQLdb'</span>,</span><br><span class="line">            host=<span class="string">'192.168.23.1'</span>,</span><br><span class="line">            db = <span class="string">'baike'</span>,</span><br><span class="line">            user = <span class="string">'root'</span>,</span><br><span class="line">            passwd = <span class="string">'password'</span>,</span><br><span class="line">            cursorclass = MySQLdb<span class="class">.cursors</span><span class="class">.DictCursor</span>,</span><br><span class="line">            charset = <span class="string">'utf8'</span>,</span><br><span class="line">            use_unicode = True</span><br><span class="line">        )</span><br><span class="line"> </span><br><span class="line">        self<span class="class">.r</span> = <span class="function"><span class="title">Redis</span><span class="params">(host=<span class="string">'localhost'</span>, port=<span class="number">6379</span>, db=<span class="number">0</span>)</span></span></span><br><span class="line">        self<span class="class">.r</span><span class="class">.flushdb</span>()</span><br><span class="line"> </span><br><span class="line">        conn = MySQLdb.<span class="function"><span class="title">connect</span><span class="params">(host=<span class="string">"127.0.0.1"</span>,user=<span class="string">"root"</span>,passwd=<span class="string">"password"</span>,db=<span class="string">"baike"</span>,charset=<span class="string">"utf8"</span>)</span></span></span><br><span class="line">        <span class="attribute">cursor</span> = conn.<span class="function"><span class="title">cursor</span><span class="params">()</span></span></span><br><span class="line">        result = <span class="attribute">cursor</span>.<span class="function"><span class="title">execute</span><span class="params">(<span class="string">"select bk_name from baikeinfo"</span>)</span></span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> row <span class="keyword">in</span> <span class="attribute">cursor</span>.<span class="function"><span class="title">fetchall</span><span class="params">()</span></span>:</span><br><span class="line">            self<span class="class">.r</span><span class="class">.set</span>(row[<span class="number">0</span>],<span class="string">'1'</span>)</span><br><span class="line"> </span><br><span class="line">     def <span class="function"><span class="title">process_item</span><span class="params">(self, item, spider)</span></span>:</span><br><span class="line">         global COUNT</span><br><span class="line">         COUNT += <span class="number">1</span></span><br><span class="line">         query = self<span class="class">.dbpool</span><span class="class">.runInteraction</span>(self._conditional_insert, item)</span><br><span class="line">         return item</span><br><span class="line"> </span><br><span class="line">     def _conditional_insert(self, tx, item):</span><br><span class="line">         <span class="keyword">if</span> item.<span class="function"><span class="title">get</span><span class="params">(<span class="string">'name'</span>)</span></span>:</span><br><span class="line">            name = item.<span class="function"><span class="title">get</span><span class="params">(<span class="string">'name'</span>)</span></span></span><br><span class="line">            <span class="keyword">if</span> self<span class="class">.r</span><span class="class">.get</span>(name)== None:</span><br><span class="line">                tx.<span class="function"><span class="title">execute</span><span class="params">(<span class="string">'insert into baikeinfo (bk_name, bk_desc, bk_link) values (%s, %s, %s)'</span>, (item[<span class="string">'name'</span>], item[<span class="string">'desc'</span>], item[<span class="string">'link'</span>])</span></span>)</span><br><span class="line">                self<span class="class">.r</span><span class="class">.set</span>(name,name)</span><br></pre></td></tr></table></figure>
<p><strong>5. 运行效果展示</strong><br>以百度百科词条”龙虾”为例。<br>提取出的结果如下:</p>
<ol>
<li>name: 龙虾</li>
<li>desc: 龙虾（学名：Palinuridae）是节肢动物门甲壳纲十足目龙虾科4个属19种龙虾的通称。又名大虾、龙头虾、虾魁、海虾等。它头胸部较粗大，外壳坚硬，色彩斑斓，腹部短小，体长一般在20厘米～40厘米之间，重0.5公斤上下，无螯，是虾类中最大的一类。最重的能达到5公斤以上，人称龙虾虎。体呈粗圆筒状，背腹稍平扁，头胸甲发达，坚厚多棘，前缘中央有一对强大的眼上棘，具封闭的鳃室。主要分布于热带海域，是名贵海产品。中国已发现8种，以淡水龙虾<a href="http://doc.scrapy.org/en/1.0/intro/overview.html" target="_blank" rel="external">1</a> 产量较大。2014年9月，日本三重县鸟羽市答志岛出现一只雌雄同体的龙虾。其左半身是红褐色，右半身是黑色。[2]</li>
<li>link: <a href="http://baike.baidu.com/subview/30404/13860190.htm" target="_blank" rel="external">http://baike.baidu.com/subview/30404/13860190.htm</a></li>
</ol>
<p>关于quantmod库的更多信息，可以阅读以下材料。</p>
<ol>
<li><a href="http://doc.scrapy.org/en/1.0/intro/overview.html" target="_blank" rel="external">Scrapy 1.0 Documentation</a></li>
</ol>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2015/08/13/20150813.R-quantmod-lib/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">利用R语言的quantmod包获取并展示股票数据</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">分享到：</span>
		<a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
		<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>



<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="20150817-Scrapy-BaikeSpider-md" data-title="基于scrapy构建百科爬虫" data-url="http://yoursite.com/2015/08/17/20150817-Scrapy-BaikeSpider-md/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"faweeky"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2015 猫叔的博客
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>